{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31cc64-fa85-4869-8e17-3a66c5624fbf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "# import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import Predictive\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "from tqdm  import tqdm\n",
    "from pyhelpers.store import save_figure\n",
    "from maf_gp import model, model_n, cov_matrix_emulator, prior_predict, posterior_predict\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "matplotlib.rcParams[\"axes.formatter.limits\"] = [-4,4]\n",
    "matplotlib.rcParams[\"font.size\"] = 14\n",
    "matplotlib.rcParams[\"font.family\"] = 'sans-serif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce85560c",
   "metadata": {},
   "source": [
    "## Prepare data and posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60392a2c-9b4d-4c83-82d8-f7bc79c0dbf8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path of file of posterior samples (need to change for the file of saved posterior samples)\n",
    "file_path = Path(\"results_mcmc/bias_E1_hv_2025_03_08_16_36_56_MAF_linear_E2_10285_300.h5\")\n",
    "f = h5py.File(file_path, 'r')\n",
    "\n",
    "# path of data folder (need to change for horizontal prediction or vertical prediction)\n",
    "data_path = Path(\"./data_extension_v\")\n",
    "# data for which loading angles to use (need to change according to requirement)\n",
    "angles = [45, 90, 135] \n",
    "# loading angle need to predict\n",
    "angle_value = 45\n",
    "# figure save format, dpi\n",
    "fig_format = 'jpeg'\n",
    "dpi = 300\n",
    "# folder to save figures etc.\n",
    "if len(angles) == 3:\n",
    "    fig_path = Path(\"figures_bias_E1\")\n",
    "else:\n",
    "    fig_path = Path(\"figures_bias_E1_leave_out\")\n",
    "\n",
    "fig_path.mkdir(exist_ok=True)\n",
    "\n",
    "# direction\n",
    "direction = data_path.stem[-1]\n",
    "\n",
    "# experimental data\n",
    "input_xy_exp_l = []\n",
    "data_exp_l = []\n",
    "for file_load_angle, file_ext in zip( sorted(data_path.glob(\"input_load_angle_exp_*\")),\n",
    "                sorted(data_path.glob(\"data_extension_exp_*\")) ):\n",
    "    load_angle = np.loadtxt(file_load_angle, delimiter=\",\")\n",
    "    if (np.abs(np.rad2deg(load_angle[0,1]) - np.array(angles)) < 1e-6).any():\n",
    "        input_xy_exp_l.append(load_angle)\n",
    "        data_exp_l.append(np.loadtxt(file_ext, delimiter=\",\").mean(axis=1))\n",
    "\n",
    "if len(input_xy_exp_l) > 0: \n",
    "    input_xy_exp = jnp.concatenate(input_xy_exp_l, axis=0)\n",
    "    data_exp = jnp.concatenate(data_exp_l, axis=0)\n",
    "    \n",
    "num_exp = len(input_xy_exp_l)\n",
    "data_size_exp = [i.shape[0] for i in input_xy_exp_l]\n",
    "\n",
    "# experiment date for the prediction loading angle\n",
    "input_xy_exp_plt = []\n",
    "data_exp_plt = []\n",
    "for file_load_angle, file_ext in zip( sorted(data_path.glob(\"input_load_angle_exp_*\")),\n",
    "                             sorted(data_path.glob(\"data_extension_exp_*\")) ):\n",
    "    load_angle = np.loadtxt(file_load_angle, delimiter=\",\")\n",
    "    if np.abs(np.rad2deg(load_angle[0,1]) - angle_value) < 1e-6:\n",
    "        input_xy_exp_plt.append(load_angle)\n",
    "        data_exp_plt.append(np.loadtxt(file_ext, delimiter=\",\").mean(axis=1))    \n",
    "\n",
    "# simulation data\n",
    "input_xy_sim = jnp.array(np.loadtxt(data_path / \"input_load_angle_sim.txt\", delimiter=\",\"))\n",
    "input_theta_sim = jnp.array(np.loadtxt(data_path / \"input_theta_sim.txt\", delimiter=\",\"))\n",
    "data_sim = jnp.array(np.loadtxt(data_path / \"data_extension_sim.txt\", delimiter=\",\")).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d82f3",
   "metadata": {},
   "source": [
    "## Plot prior and posterior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6e9e1-6534-4b09-8294-d405602039dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior_dist = [] \n",
    "#prior_dist.append(dist.Normal(148800, 2000))\n",
    "#prior_dist.append(dist.Normal(9190, 100))\n",
    "#prior_dist.append(dist.Normal(0.34, 0.01))\n",
    "#prior_dist.append(dist.Normal(0.44, 0.01))\n",
    "#prior_dist.append(dist.Normal(5060, 70))\n",
    "\n",
    "#prior_dist.append(dist.Normal(161000, 2000))\n",
    "#prior_dist.append(dist.Normal(11380, 200))\n",
    "#prior_dist.append(dist.Normal(0.32, 0.01))\n",
    "#prior_dist.append(dist.Normal(0.43, 0.01))\n",
    "#prior_dist.append(dist.Normal(5170, 70))\n",
    "\n",
    "prior_dist.append(dist.Normal(154900, 5050))\n",
    "prior_dist.append(dist.Normal(10285, 300)) # changes here\n",
    "prior_dist.append(dist.Normal(0.33, 0.015))\n",
    "prior_dist.append(dist.Normal(0.435, 0.0125))\n",
    "prior_dist.append(dist.Normal(5115, 100))\n",
    "\n",
    "keys = ['E_1', 'E_2', 'v_12', 'v_23', 'G_12']\n",
    "x_labels = ['$E_1$ [MPa]', '$E_2$ [MPa]', '$\\\\nu_{12}$ [-]', '$\\\\nu_{23}$ [-]', '$G_{12}$ [MPa]'] \n",
    "dic_0 = {}\n",
    "dic = {}\n",
    "fig, ax = plt.subplots(nrows=1, ncols=len(keys), figsize=(20,4), layout='constrained')\n",
    "for i in range(len(keys)):\n",
    "    dic_0[x_labels[i]] = f[keys[i]] \n",
    "    dic[x_labels[i]] = f[keys[i]][::3]\n",
    "    # fig, ax = plt.subplots()\n",
    "    if i==0:\n",
    "        x_prior = jnp.linspace(140000,175000)\n",
    "    else:\n",
    "        if i==1:\n",
    "            x_prior = jnp.linspace(6000,13000)\n",
    "        else:     \n",
    "            if i==2:\n",
    "               x_prior = jnp.linspace(0.25,0.4)\n",
    "            else:\n",
    "                if i==3:\n",
    "                   x_prior = jnp.linspace(0.35,0.5)\n",
    "                else:                  \n",
    "                    x_prior = jnp.linspace(4600,5600)    \n",
    "    ax[i].plot(x_prior, jnp.exp(prior_dist[i].log_prob(x_prior)), color='tab:green', lw=1.5, label='Prior')   \n",
    "    ax[i].hist(f[keys[i]], bins=30, rwidth=0.9, color=\"tab:blue\", density=True, label='Posterior')\n",
    "    ax[i].set_xlabel(x_labels[i])\n",
    "    if i == 0:\n",
    "        ax[i].set_xticks(np.arange(1.4, 1.75, 0.1)* 1e5)\n",
    "        ax[i].set_ylabel(\"PDF\")\n",
    "        ax[i].legend()\n",
    "    # ax[i].ticklabel_format(scilimits=(-5,5))\n",
    "# fig.tight_layout()\n",
    "\n",
    "if len(angles) == 3:\n",
    "    suffix = data_path.stem[-1]\n",
    "else:\n",
    "    suffix = data_path.stem[-1]\n",
    "    for i in angles:\n",
    "        suffix = suffix + '_' + str(i)\n",
    "\n",
    "fig.savefig(fig_path.joinpath(\"inference_theta_linear_bias_E1\" + suffix[1:] + \".\" + fig_format),\n",
    "            dpi=dpi, transparent=True)\n",
    "save_figure(fig, str(fig_path.joinpath(\"inference_theta_linear_bias_E1\" + suffix[1:] + \".svg\")), verbose=True, conv_svg_to_emf=True)\n",
    "\n",
    "df_0 = pd.DataFrame(dic_0)\n",
    "post_stats = {\"mean\": df_0.mean(),\n",
    "             \"variance\": df_0.var(),\n",
    "              \"std\": df_0.std()}\n",
    "pd.concat(post_stats, axis=1).to_csv(fig_path.joinpath(\"inference_theta_linear_bias_E1_stats\" + suffix[1:] + \".csv\"))\n",
    "\n",
    "#pair plots\n",
    "df = pd.DataFrame(dic)\n",
    "# df.columns = x_labels\n",
    "grid = sns.pairplot(df, kind='scatter', diag_kind='hist')\n",
    "grid.savefig(\"inference_theta_grid_linear_bias_E1_\" + suffix + \".\" + fig_format, dpi=dpi, transparent=True)\n",
    "\n",
    "# bias \n",
    "keys_b = []\n",
    "x_labels_b = []\n",
    "dic_b = {}\n",
    "for i in range(len(input_xy_exp_l)):\n",
    "    keys_b.append(\"b_\"+str(i+1)+\"_E1\")\n",
    "    x_labels_b.append(\"$b_{E_1,\"+str(i+1)+\"}$ [MPa]\")\n",
    "    dic_b[\"$b_{E_1,\"+str(i+1)+\"}$ [MPa]\"] = f[keys_b[i]]\n",
    "\n",
    "if len(angles) < 3:\n",
    "    fig_b, ax_b = plt.subplots(nrows=1, ncols=len(keys_b), figsize=(len(keys_b)*4, 4), layout='constrained')\n",
    "    for i in range(len(keys_b)):\n",
    "        # fig, ax = plt.subplots()\n",
    "        x_prior = np.linspace(-3000, 3000, 100)\n",
    "        ax_b[i].plot(x_prior, np.exp(dist.Normal(0,1000).log_prob(x_prior)), color='tab:green', lw=1.5, label='Prior')   \n",
    "        ax_b[i].hist(f[keys_b[i]], bins=30, rwidth=0.9, color='tab:blue', density=True, label='posterior')\n",
    "        ax_b[i].set_xlabel(x_labels_b[i])\n",
    "        if i == 0:\n",
    "            ax_b[i].legend()\n",
    "            ax_b[i].set_ylabel(\"PDF\")\n",
    "\n",
    "    # fig_b, ax_b = plt.subplots(nrows=2, ncols=4, figsize=(16, 8), layout='constrained')\n",
    "    # for i in range(2):\n",
    "    #     for j in range(4):\n",
    "    #         # fig, ax = plt.subplots()\n",
    "    #         x_prior = np.linspace(-3000, 3000, 100)\n",
    "    #         ax_b[i,j].plot(x_prior, np.exp(dist.Normal(0,1000).log_prob(x_prior)), color='tab:green', lw=1.5, label='Prior')   \n",
    "    #         ax_b[i,j].hist(f[keys_b[i*4+j]], bins=30, rwidth=0.9, color='tab:blue', density=True, label='Posterior')\n",
    "    #         ax_b[i,j].set_xlabel(x_labels_b[i*4+j])\n",
    "    #         # ax[i,j].ticklabel_format(scilimits=(-5,5))\n",
    "    #         if i==0 and j==0:\n",
    "    #             ax_b[i,j].legend()\n",
    "    #             ax_b[i,j].set_ylabel(\"PDF\")\n",
    "    #         if i==1 and j==0:\n",
    "    #             ax_b[i,j].set_ylabel(\"PDF\")\n",
    "else:\n",
    "    fig_b, ax_b = plt.subplots(nrows=3, ncols=3, figsize=(12, 12), layout=\"constrained\")\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if i==2 and j==2:\n",
    "                ax_b[i,j].set_axis_off()\n",
    "                break\n",
    "            x_prior = np.linspace(-3000, 3000, 100)\n",
    "            ax_b[i,j].plot(x_prior, np.exp(dist.Normal(0,1000).log_prob(x_prior)), color='tab:green', lw=1.5, label='Prior')\n",
    "            ax_b[i,j].hist(f[keys_b[i*3+j]], bins=30, rwidth=0.9, color='tab:blue', density=True, label='Posterior')\n",
    "            ax_b[i,j].set_xlabel(x_labels_b[i*3+j])\n",
    "            if i==0 and j==0:\n",
    "                ax_b[i,j].legend()\n",
    "                ax_b[i,j].set_ylabel(\"PDF\")\n",
    "            if (i==1 or i==2) and j==0:\n",
    "                ax_b[i,j].set_ylabel(\"PDF\")\n",
    "\n",
    "df_b = pd.DataFrame(dic_b)\n",
    "post_stats_b = {\"mean\": df_b.mean(),\n",
    "                \"variance\": df_b.var(),\n",
    "                \"std\": df_b.std()}\n",
    "pd.concat(post_stats_b, axis=1).to_csv(fig_path.joinpath(\"inference_b_linear_bias_E1_stats\" + suffix[1:] + \".csv\"))\n",
    "\n",
    "fig_b.savefig(fig_path.joinpath(\"inference_b_linear_bias_E1\" + suffix[1:] + \".\" + fig_format),\n",
    "              dpi=dpi, transparent=True)\n",
    "save_figure(fig_b, str(fig_path.joinpath(\"inference_b_linear_bias_E1\" + suffix[1:] + \".svg\")), verbose=True, conv_svg_to_emf=True)\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a72d2-50d9-424f-92a2-c115a2bc7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dist_hyper = [] \n",
    "prior_dist_hyper.append(dist.Normal(0, 0.01))\n",
    "prior_dist_hyper.append(dist.Exponential(20.))\n",
    "prior_dist_hyper.append(dist.LogNormal(1.5, 0.5))\n",
    "prior_dist_hyper.append(dist.LogNormal(0.34, 0.5))\n",
    "prior_dist_hyper.append(dist.LogNormal(11., 0.5))\n",
    "prior_dist_hyper.append(dist.LogNormal(8.3, 0.5))\n",
    "prior_dist_hyper.append(dist.LogNormal(-0.80, 0.5))\n",
    "prior_dist_hyper.append(dist.LogNormal(-0.80, 0.5))\n",
    "prior_dist_hyper.append(dist.LogNormal(7.7, 0.5))\n",
    "prior_dist_hyper.append(dist.Exponential(100.))\n",
    "\n",
    "# hyper-parameters\n",
    "keys_hyper = ['mu_emulator', 'sigma_emulator', 'lambda_P', 'lambda_alpha', 'lambda_E1', \n",
    "              'lambda_E2', 'lambda_v12', 'lambda_v23', 'lambda_G12', 'sigma_measure']\n",
    "x_labels_hyper = [r'$\\beta$ [mm/kN]', r'$\\sigma_{\\eta}$ [mm]', r'$\\lambda_{\\eta,P}$ [kN]', r'$\\lambda_{\\eta,\\alpha}$ [rad]', \n",
    "                  r'$\\lambda_{\\eta,E_1}$ [MPa]', r'$\\lambda_{\\eta,E_2}$ [MPa]', r'$\\lambda_{\\eta,v_{12}}$ [-]', r'$\\lambda_{\\eta,v_{23}}$ [-]', \n",
    "                  r'$\\lambda_{\\eta,G_{12}}$ [GPa]', r'$\\sigma_{\\epsilon}$ [mm/$\\sqrt{\\mathrm{kN}}$]']\n",
    "dic_hyper_0 = {}\n",
    "dic_hyper = {}\n",
    "fig_hyper, ax_hyper = plt.subplots(nrows=2, ncols=5, figsize=(20,8), layout='constrained')\n",
    "for i in range(2):\n",
    "    for j  in range(5):\n",
    "        dic_hyper_0[x_labels_hyper[i*5+j]] = f[keys_hyper[i*5+j]]\n",
    "        dic_hyper[x_labels_hyper[i*5+j]] = f[keys_hyper[i*5+j]][::3]\n",
    "        # fig, ax = plt.subplots()\n",
    "        samples_prior = prior_dist_hyper[i*5+j].sample(random.PRNGKey(0), (5000,))\n",
    "        x_prior = jnp.linspace(samples_prior.min(), samples_prior.max(), 100)\n",
    "        ax_hyper[i,j].plot(x_prior, jnp.exp(prior_dist_hyper[i*5+j].log_prob(x_prior)), color='tab:green', lw=1.5, label='Prior')  \n",
    "        ax_hyper[i,j].hist(f[keys_hyper[i*5+j]], bins=30, rwidth=0.9, color='tab:blue', density=True, label='Posterior')\n",
    "        ax_hyper[i,j].set_xlabel(x_labels_hyper[i*5+j])\n",
    "        if i==0 and j==0:\n",
    "            ax_hyper[i,j].legend(loc='upper left')\n",
    "            ax_hyper[i,j].set_ylabel(\"PDF\")\n",
    "        if i==1 and j==0:\n",
    "            ax_hyper[i,j].set_ylabel(\"PDF\")\n",
    "        if i*5+j == 0:\n",
    "            ax_hyper[i,j].set_ylim([0,60])\n",
    "        if i*5+j == 1:\n",
    "            ax_hyper[i,j].set_ylim([0,50])\n",
    "            ax_hyper[i,j].set_xlim([-0.02,0.2])\n",
    "        if i*5+j == 9:\n",
    "            ax_hyper[i,j].set_ylim([0,200])\n",
    "            ax_hyper[i,j].set_xlim([-0.002,0.02])\n",
    "        if i*5+j == 3:\n",
    "            ax_hyper[i,j].set_xlim([-0.1,4]) \n",
    "        if i*5+j == 4:\n",
    "            ax_hyper[i,j].set_xlim([-0.1e5,2e5]) \n",
    "        # ax[i].ticklabel_format(scilimits=(-5,5))\n",
    "# fig_hyper.tight_layout()\n",
    "\n",
    "fig_hyper.savefig(fig_path.joinpath(\"inference_hyper_linear_bias_E1\" + suffix[1:] + \".\" + fig_format),\n",
    "                  dpi=dpi, transparent=True)\n",
    "save_figure(fig_hyper, str(fig_path.joinpath(\"inference_hyper_linear_bias_E1\" + suffix[1:] + \".svg\")), verbose=True, conv_svg_to_emf=True)\n",
    "\n",
    "\n",
    "df_hyper_0 = pd.DataFrame(dic_hyper_0)\n",
    "post_stats_hyper = {\"mean\": df_hyper_0.mean(),\n",
    "                     \"variance\": df_hyper_0.var(),\n",
    "                    \"std\": df_hyper_0.std()}\n",
    "pd.concat(post_stats_hyper, axis=1).to_csv(fig_path.joinpath(\"inference_hyper_linear_bias_E1_stats\" + suffix[1:] + \".csv\"))\n",
    "\n",
    "# df_hyper = pd.DataFrame(dic_hyper)\n",
    "# # df_hyper.columns = x_labels_hyper\n",
    "# grid_hyper = sns.pairplot(df_hyper)\n",
    "# grid_hyper.savefig(\"inference_hyper_grid_linear_bias_E1_\" + suffix + \".\" + fig_format, dpi=dpi, transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317c434",
   "metadata": {},
   "source": [
    "## Prior prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903742a-193e-42c5-91eb-795591370655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior prediction\n",
    "# angle_value = 90 # 2*jnp.pi/4\n",
    "n_loads = 100\n",
    "samples_load = jnp.linspace(0,10,n_loads)\n",
    "samples_angle = jnp.ones(n_loads) * jnp.deg2rad(angle_value)\n",
    "test_xy = jnp.stack((samples_load, samples_angle), axis=1)\n",
    "\n",
    "prior = Predictive(model_n, num_samples=5000)(\n",
    "    random.PRNGKey(12345), input_xy_exp_l, input_xy_sim, input_theta_sim, data_exp_l, data_sim, add_bias_E1=True\n",
    ")\n",
    "rng_key, rng_key_predict = random.split(random.PRNGKey(12345))\n",
    "\n",
    "# post samples of FE parameters\n",
    "keys = ['E_1', 'E_2', 'v_12', 'v_23', 'G_12']\n",
    "samples_prior_theta = []\n",
    "for key in keys:\n",
    "    samples_prior_theta.append(prior[key])\n",
    "\n",
    "samples_prior_theta = jnp.stack(samples_prior_theta, axis=1)\n",
    "\n",
    "samples_prior_mean_emulator = prior['mu_emulator']\n",
    "samples_prior_stdev_emulator = prior['sigma_emulator']\n",
    "\n",
    "samples_prior_length_xy = []\n",
    "keys = ['lambda_P', 'lambda_alpha']\n",
    "for key in keys:\n",
    "    samples_prior_length_xy.append(prior[key])\n",
    "\n",
    "samples_prior_length_xy = jnp.stack(samples_prior_length_xy, axis=1)\n",
    "\n",
    "samples_prior_length_theta = []\n",
    "keys = ['lambda_E1', 'lambda_E2', 'lambda_v12', 'lambda_v23', 'lambda_G12']\n",
    "for key in keys:\n",
    "    samples_prior_length_theta.append(prior[key])\n",
    "\n",
    "samples_prior_length_theta = jnp.stack(samples_prior_length_theta, axis=1)\n",
    "\n",
    "rng_keys_predict = random.split(rng_key_predict, samples_prior_theta.shape[0])\n",
    "rng_keys = random.split(rng_key, samples_prior_theta.shape[0])\n",
    "\n",
    "means_prior, stdevs_prior, predictions_prior = [], [], []\n",
    "for ind in tqdm(range(samples_prior_theta.shape[0])):\n",
    "    rng_key = rng_keys_predict[ind]\n",
    "    test_theta = samples_prior_theta[ind]\n",
    "    test_theta = test_theta.at[0].add(dist.Normal(0,1000).sample(rng_keys[ind])) # add bias\n",
    "    # test_theta = test_theta.at[0].add(dist.Normal(0,dist.Exponential(0.001).sample(rng_keys[ind])).sample(rng_keys[ind]))\n",
    "    mean_emulator = samples_prior_mean_emulator[ind]\n",
    "    stdev_emulator = samples_prior_stdev_emulator[ind]\n",
    "    length_xy = samples_prior_length_xy[ind]\n",
    "    length_theta = samples_prior_length_theta[ind]\n",
    "\n",
    "    mean, stdev, prediction = prior_predict(rng_key, input_xy_sim, input_theta_sim, data_sim, test_xy, test_theta, \n",
    "                                            mean_emulator, stdev_emulator, length_xy, length_theta, direction=direction)\n",
    "    means_prior.append(mean)\n",
    "    stdevs_prior.append(stdev)\n",
    "    predictions_prior.append(prediction)\n",
    "    \n",
    "    # if (ind+1)%500 == 0:\n",
    "    #     print(f\"#Iteration: {ind+1}\")\n",
    "\n",
    "means_prior = jnp.stack(means_prior, axis=0)\n",
    "stdevs_prior = jnp.stack(stdevs_prior, axis=0)\n",
    "predictions_prior = jnp.stack(predictions_prior, axis=0)\n",
    "\n",
    "mean_prediction_prior = np.mean(means_prior, axis=0)\n",
    "percentiles_prior = np.percentile(predictions_prior, [2.5, 97.5], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5621981-5f9d-43b5-86dd-04a1b729f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_prior = np.percentile(predictions_prior, [2.5, 97.5], axis=0)\n",
    "\n",
    "# stdevs_prior_total = np.sqrt(np.mean(stdevs_prior**2 , axis=0) + np.var(means_prior, axis=0))\n",
    "# percentiles_prior[0] = np.mean(means_prior, axis=0) - 2*stdevs_prior_total\n",
    "# percentiles_prior[0] = np.clip(percentiles_prior[0], a_min=0, a_max=None)\n",
    "# percentiles_prior[1] = np.mean(means_prior, axis=0) + 2*stdevs_prior_total\n",
    "\n",
    "from scipy.interpolate import make_interp_spline\n",
    "gap = 8\n",
    "\n",
    "n_neg = (percentiles_prior[0] < 0.008).sum()\n",
    "if direction == 'v' and angle_value == 90:\n",
    "    n_neg = 1\n",
    "\n",
    "if direction != 'v' or angle_value != 135:\n",
    "    x = np.concatenate((samples_load[:n_neg:n_neg], samples_load[n_neg::gap]))\n",
    "    y = np.concatenate((percentiles_prior[0][:n_neg:n_neg], percentiles_prior[0][n_neg::gap]))\n",
    "    bspl = make_interp_spline(x, y, k=2)\n",
    "    percentiles_prior[0] = bspl(samples_load)\n",
    "    bspl = make_interp_spline(samples_load[::gap], percentiles_prior[1][::gap], k=2)\n",
    "    percentiles_prior[1] = bspl(samples_load)\n",
    "else:\n",
    "    n_neg = (percentiles_prior[1] > -0.005).sum()\n",
    "    x = np.concatenate((samples_load[:n_neg:n_neg], samples_load[n_neg::gap]))\n",
    "    y = np.concatenate((percentiles_prior[1][:n_neg:n_neg], percentiles_prior[1][n_neg::gap]))\n",
    "    bspl = make_interp_spline(x, y, k=2)\n",
    "    # bspl = make_interp_spline(samples_load[::gap], percentiles_prior[1][::gap], k=2)\n",
    "    percentiles_prior[1] = bspl(samples_load)\n",
    "    bspl = make_interp_spline(samples_load[::gap], percentiles_prior[0][::gap], k=2)\n",
    "    percentiles_prior[0] = bspl(samples_load)\n",
    "\n",
    "df_prior = pd.DataFrame()\n",
    "df_prior['samples_load'] = samples_load\n",
    "df_prior['percentiles_prior_l'] = percentiles_prior[0, :]\n",
    "df_prior['percentiles_prior_u'] = percentiles_prior[1, :]\n",
    "df_prior['mean_prediction_prior'] = mean_prediction_prior\n",
    "df_prior.to_csv(fig_path.joinpath(\"prior_prediction_\"+str(angle_value)+\"deg_linear_bias_E1_\" + suffix +\".csv\"))\n",
    "\n",
    "# make plots\n",
    "fig_prior, ax_prior = plt.subplots(figsize=(5,5), constrained_layout=True)\n",
    "\n",
    "# plot 95% confidence level of predictions\n",
    "ax_prior.fill_betweenx(samples_load, percentiles_prior[0, :], percentiles_prior[1, :], color=\"lightgreen\", label=r'95% interval')\n",
    "# plot mean prediction\n",
    "ax_prior.plot(mean_prediction_prior, samples_load, \"green\", ls=\"dashed\", lw=1.5, label='Prior mean')\n",
    "# plot data\n",
    "sz = 3\n",
    "for i in range(len(input_xy_exp_plt)):\n",
    "    ax_prior.plot(data_exp_plt[i], input_xy_exp_plt[i][:,0], \"o\", markersize=sz, label='Data '+str(i+1))\n",
    "    \n",
    "ax_prior.set(xlabel=\"Extension [mm]\", ylabel=\"Load [kN]\", title=\"Prior prediction ($\" + str(angle_value) + r\"^\\circ$)\")\n",
    "ax_prior.legend(fontsize=12)\n",
    "if angle_value == 45:\n",
    "    ax_prior.set_xlim(-0.005, 0.09)\n",
    "if angle_value == 90:\n",
    "    ax_prior.set_xlim(-0.02, 0.125)\n",
    "if angle_value == 135:\n",
    "    ax_prior.set_xlim(-0.055, 0.09)\n",
    "fig_prior.savefig(fig_path.joinpath(\"prior_prediction_\"+str(angle_value)+\"deg_linear_bias_E1_\" + suffix + \".\" + fig_format),\n",
    "                  dpi=dpi, transparent=True)\n",
    "# fig, ax = plt.subplots(figsize=(8, 6), constrained_layout=True)\n",
    "# for i in range(500):\n",
    "#     ax.plot(predictions_prior[i], samples_load, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2fd538",
   "metadata": {},
   "source": [
    "## Posterior prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa4f97-ad2a-4ed0-b75d-a384ddc1be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior prediction\n",
    "rng_key, rng_key_predict = random.split(rng_key_predict)\n",
    "\n",
    "# post samples of FE parameters\n",
    "keys = ['E_1', 'E_2', 'v_12', 'v_23', 'G_12']\n",
    "samples_post_theta = []\n",
    "for key in keys:\n",
    "    samples_post_theta.append(jnp.array(f[key]))\n",
    "\n",
    "samples_post_theta = jnp.stack(samples_post_theta, axis=1)\n",
    "\n",
    "samples_post_mean_emulator = jnp.array(f['mu_emulator'])\n",
    "samples_post_stdev_emulator = jnp.array(f['sigma_emulator'])\n",
    "\n",
    "samples_post_length_xy = []\n",
    "keys = ['lambda_P', 'lambda_alpha']\n",
    "for key in keys:\n",
    "    samples_post_length_xy.append(jnp.array(f[key]))\n",
    "\n",
    "samples_post_length_xy = jnp.stack(samples_post_length_xy, axis=1)\n",
    "\n",
    "samples_post_length_theta = []\n",
    "keys = ['lambda_E1', 'lambda_E2', 'lambda_v12', 'lambda_v23', 'lambda_G12']\n",
    "for key in keys:\n",
    "    samples_post_length_theta.append(jnp.array(f[key]))\n",
    "\n",
    "samples_post_length_theta = jnp.stack(samples_post_length_theta, axis=1)\n",
    "\n",
    "samples_post_stdev_measure = jnp.array(f['sigma_measure'])\n",
    "\n",
    "rng_keys_predict = random.split(rng_key_predict, samples_post_theta.shape[0])\n",
    "rng_keys = random.split(rng_key, samples_post_theta.shape[0])\n",
    "\n",
    "means_post, stdevs_post, predictions_post = [], [], []\n",
    "for ind in tqdm(range(samples_post_theta.shape[0])):\n",
    "    rng_key = rng_keys_predict[ind]\n",
    "    test_theta_0 = samples_post_theta[ind]\n",
    "    test_theta = test_theta_0.at[0].add(dist.Normal(0,1000).sample(rng_keys[ind])) # add bias\n",
    "    # test_theta = test_theta_0.at[0].add(dist.Normal(0,f['sigma_b_E1'][ind]).sample(rng_keys[ind]))\n",
    "    mean_emulator = samples_post_mean_emulator[ind]\n",
    "    stdev_emulator = samples_post_stdev_emulator[ind]\n",
    "    length_xy = samples_post_length_xy[ind]\n",
    "    length_theta = samples_post_length_theta[ind]\n",
    "    stdev_measure = samples_post_stdev_measure[ind]\n",
    "\n",
    "    input_theta_exp = []\n",
    "    for i in range(num_exp):\n",
    "        # theta_b = theta\n",
    "        theta_b = test_theta_0.at[0].add(jnp.array(f[\"b_\"+str(i+1)+\"_E1\"][ind]))\n",
    "        input_theta_exp.append(jnp.tile(theta_b, (data_size_exp[i],1)))\n",
    "    input_theta_exp = jnp.concatenate(input_theta_exp, axis=0 ) \n",
    "    \n",
    "    mean, stdev, prediction = posterior_predict(rng_key, input_xy_exp, input_xy_sim, input_theta_exp, input_theta_sim, data_exp, data_sim,\n",
    "                                      test_xy, test_theta, mean_emulator, stdev_emulator, length_xy, length_theta, stdev_measure, direction=direction)\n",
    "    \n",
    "    means_post.append(mean)\n",
    "    stdevs_post.append(stdev)\n",
    "    predictions_post.append(prediction)\n",
    "    \n",
    "    # if (ind+1)%500 == 0:\n",
    "    #     print(f\"#Iteration: {ind+1}\")\n",
    "\n",
    "means_post = jnp.stack(means_post, axis=0)\n",
    "stdevs_post = jnp.stack(stdevs_post, axis=0)\n",
    "predictions_post = jnp.stack(predictions_post, axis=0)\n",
    "\n",
    "mean_prediction_post = np.mean(predictions_post, axis=0)\n",
    "percentiles_post = np.percentile(predictions_post, [2.5, 97.5], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740d24e-97aa-41ac-94da-592219a00d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post = pd.DataFrame()\n",
    "df_post['samples_load'] = samples_load\n",
    "df_post['percentiles_post_l'] = percentiles_post[0, :]\n",
    "df_post['percentiles_post_u'] = percentiles_post[1, :]\n",
    "df_post['mean_prediction_post'] = mean_prediction_post\n",
    "df_post.to_csv(fig_path.joinpath(\"post_prediction_\"+str(angle_value)+\"deg_linear_bias_E1_\" + suffix +\".csv\"))\n",
    "\n",
    "# make plots\n",
    "fig_post, ax_post = plt.subplots(figsize=(5,5), constrained_layout=True)\n",
    "\n",
    "# plot 90% confidence level of predictions\n",
    "ax_post.fill_betweenx(samples_load, percentiles_post[0, :], percentiles_post[1, :], color=\"lightblue\", label=r\"95% interval\")\n",
    "# plot mean prediction\n",
    "ax_post.plot(mean_prediction_post, samples_load, \"blue\", ls=\"solid\", lw=1.5, label=\"Posterior mean\")\n",
    "# plot data\n",
    "sz=2\n",
    "for i in range(len(input_xy_exp_plt)):\n",
    "    ax_post.plot(data_exp_plt[i], input_xy_exp_plt[i][:,0], \"o\", markersize=sz, label='Data '+str(i+1))\n",
    "\n",
    "ax_post.set(xlabel=\"Extension [mm]\", ylabel=\"Load [kN]\", title=\"Posterior prediction ($\" + str(angle_value) + r\"^\\circ$)\")\n",
    "ax_post.legend(fontsize=10)\n",
    "if angle_value == 45:\n",
    "    ax_post.set_xlim(-0.005, 0.09)\n",
    "if angle_value == 90:\n",
    "    ax_post.set_xlim(-0.02, 0.125)\n",
    "if angle_value == 135:\n",
    "    ax_post.set_xlim(-0.055, 0.09)\n",
    "fig_post.savefig(fig_path.joinpath(\"post_prediction_\"+str(angle_value)+\"deg_linear_bias_E1_\" + suffix + \".\" + fig_format),\n",
    "                 dpi=dpi, transparent=True)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 6), constrained_layout=True)\n",
    "# for i in range(500):\n",
    "#     ax.plot(predictions_post[i], samples_load, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cdf454-533b-4a48-8fe3-5a16abf2913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_post_stdevs = np.sqrt(samples_post_stdev_measure[:,None]**2 * samples_load)\n",
    "# # samples_post_stdevs = (samples_post_stdev_measure[:,None] * samples_load)\n",
    "\n",
    "# measure_error = np.random.randn(*samples_post_stdev_measure.shape)[:,None] * samples_post_stdevs\n",
    "# predictions_post_error = predictions_post + measure_error\n",
    "# mean_prediction_post_error = np.mean(predictions_post_error, axis=0)\n",
    "# percentiles_post_error = np.percentile(predictions_post_error, [2.5, 97.5], axis=0)\n",
    "\n",
    "# df_post_error = pd.DataFrame()\n",
    "# df_post_error['samples_load'] = samples_load\n",
    "# df_post_error['percentiles_post_error_l'] = percentiles_post_error[0, :]\n",
    "# df_post_error['percentiles_post_error_u'] = percentiles_post_error[1, :]\n",
    "# df_post_error['mean_prediction_post_error'] = mean_prediction_post_error\n",
    "# df_post_error.to_csv(fig_path.joinpath(\"post_prediction_error_\"+str(angle_value)+\"deg_linear_bias_E1_\" + suffix +\".csv\"))\n",
    "\n",
    "# # make plots\n",
    "# fig_post2, ax_post2 = plt.subplots(figsize=(5,5), layout='constrained')\n",
    "\n",
    "# # plot 90% confidence level of predictions\n",
    "# ax_post2.fill_betweenx(samples_load, percentiles_post_error[0, :], percentiles_post_error[1, :], color=\"lightblue\", label=r\"95% interval\")\n",
    "# # plot mean prediction\n",
    "# ax_post2.plot(mean_prediction_post_error, samples_load, \"blue\", ls=\"solid\", lw=1.5, label=\"Posterior mean\")\n",
    "# # plot data\n",
    "# sz=2\n",
    "# for i in range(len(input_xy_exp_plt)):\n",
    "#     ax_post2.plot(data_exp_plt[i], input_xy_exp_plt[i][:,0], \"o\", markersize=sz, label='Data '+str(i+1))\n",
    "\n",
    "# ax_post2.set(xlabel=\"Extension [mm]\", ylabel=\"Load [kN]\", title=\"Posterior prediction ($\" + str(angle_value) + r\"^\\circ$)\")\n",
    "# ax_post2.legend(fontsize=10)\n",
    "# if angle_value == 45:\n",
    "#     ax_post2.set_xlim(-0.005, 0.09)\n",
    "# if angle_value == 90:\n",
    "#     ax_post2.set_xlim(-0.02, 0.125)\n",
    "# if angle_value == 135:\n",
    "#     ax_post2.set_xlim(-0.055, 0.09)\n",
    "# fig_post2.savefig(fig_path.joinpath(\"post_prediction_error_\"+str(angle_value)+\"deg_linear_bais_E1_\" + suffix + \".\" + fig_format),\n",
    "#                   dpi=dpi, transparent=True)\n",
    "# # fig, ax = plt.subplots(figsize=(8, 6), constrained_layout=True)\n",
    "# # for i in range(500):\n",
    "# #     ax.plot(predictions_post_error[i], samples_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8eff12-5087-4d06-83a4-259f471e7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot prior and posterior together\n",
    "fig_all, ax_all = plt.subplots(figsize=(5,5), layout='constrained')\n",
    "ax_all.fill_betweenx(samples_load, percentiles_prior[0, :], percentiles_prior[1, :], alpha=0.75, color=\"lightgreen\", label=r'Prior 95% interval')\n",
    "ax_all.plot(mean_prediction_prior, samples_load, c=\"green\", ls=\"dashed\", lw=1.5, label='Prior mean')\n",
    "\n",
    "ax_all.fill_betweenx(samples_load, percentiles_post[0, :], percentiles_post[1, :], alpha=1, color=\"lightblue\", label=r\"Posterior 95% interval\")\n",
    "ax_all.plot(mean_prediction_post, samples_load, c=\"blue\", ls=\"solid\", lw=1.5, label=\"Posterior mean\")\n",
    "\n",
    "sz=2\n",
    "for i in range(len(input_xy_exp_plt)):\n",
    "    ax_all.plot(data_exp_plt[i], input_xy_exp_plt[i][:,0], \"o\", markersize=sz, label='Data '+str(i+1))\n",
    "\n",
    "ax_all.set(xlabel=\"Extension [mm]\", ylabel=\"Load [kN]\", title=\"Predictions ($\" + str(angle_value) + r\"^\\circ$)\")\n",
    "ax_all.legend(fontsize=10)\n",
    "if angle_value == 45:\n",
    "    ax_all.set_xlim(-0.005, 0.09)\n",
    "if angle_value == 90:\n",
    "    ax_all.set_xlim(-0.02, 0.125)\n",
    "if angle_value == 135:\n",
    "    ax_all.set_xlim(-0.055, 0.09)\n",
    "fig_all.savefig(fig_path.joinpath(\"prediction_\"+str(angle_value)+\"deg_linear_bias_E1_\" + suffix + \".\" + fig_format),\n",
    "                dpi=dpi, transparent=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

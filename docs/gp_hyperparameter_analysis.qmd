---
title: "GP Hyperparameter Analysis: Length Scales and Uncertainty Bands"
author: "Technical Reference"
date: "2025-12-13"
format:
  html:
    toc: true
    code-fold: false
    number-sections: true
---

# Overview

This document provides mathematical analysis of two key phenomena observed in the GP prediction plots:

1. **Wiggly prior realizations**: Why sampled curves from the prior can appear highly variable
2. **Narrow posterior prediction bands**: Why uncertainty intervals may appear smaller than expected

Understanding these behaviours requires examining the GP covariance structure and how uncertainty propagates through predictions.

# Length Scales and GP Smoothness

## The Squared Exponential Kernel

The covariance function implemented in `src/core/covariance.py` is a squared exponential (SE) kernel with automatic relevance determination (ARD):

$$
k(\mathbf{x}, \mathbf{x}') = \sigma_{\text{emulator}}^2 \exp\left(-\frac{(P - P')^2}{\lambda_P^2} - \frac{(\alpha - \alpha')^2}{\lambda_\alpha^2} - \sum_{i=1}^{5} \frac{(\theta_i - \theta'_i)^2}{\lambda_{\theta_i}^2}\right)
$$

where:

- $P, P'$ = Load values (kN)
- $\alpha, \alpha'$ = Angle values (radians)
- $\theta = (E_1, E_2, \nu_{12}, \nu_{23}, G_{12})$ = Material parameters
- $\lambda_P, \lambda_\alpha, \lambda_{\theta_i}$ = Length scales for each dimension
- $\sigma_{\text{emulator}}$ = Marginal standard deviation

## Correlation Decay with Distance

The length scale $\lambda_P$ defines the **characteristic distance** over which the function varies significantly. The correlation between function values at two loads $P_1$ and $P_2$ (holding other inputs fixed) is:

$$
\text{Corr}[f(P_1), f(P_2)] = \exp\left(-\frac{(P_1 - P_2)^2}{\lambda_P^2}\right)
$$

Key reference points:

| Distance $\Delta P$ | Correlation |
|---------------------|-------------|
| $0.5 \lambda_P$ | $e^{-0.25} \approx 0.78$ |
| $\lambda_P$ | $e^{-1} \approx 0.37$ |
| $2\lambda_P$ | $e^{-4} \approx 0.02$ |
| $3\lambda_P$ | $e^{-9} \approx 0.0001$ |

**Interpretation**: Points separated by more than $2\lambda_P$ are effectively independent.

## The Critical Ratio: Length Scale vs. Prediction Range

The "wiggliness" of GP samples depends on the ratio between the prediction range and the length scale.

**Number of effective independent regions**:
$$
N_{\text{regions}} \approx \frac{\text{Range}}{\lambda_P}
$$

With prediction range 0‚Äì10 kN:

| Prior Setting | Median $\lambda_P$ | $N_{\text{regions}}$ | Visual Character |
|---------------|--------------------|-----------------------|------------------|
| `mean=1.5` | $e^{1.5} \approx 4.5$ kN | ~2.2 | Moderate wiggle |
| `mean=2.5` | $e^{2.5} \approx 12.2$ kN | ~0.8 | Smooth |
| `mean=3.0` | $e^{3.0} \approx 20.1$ kN | ~0.5 | Very smooth |

### Prior Variability

The length scale prior is log-normal: $\lambda_P \sim \text{LogNormal}(\mu, \sigma)$ where we parameterise as:
$$
\lambda_P = \exp(\mu + \sigma \cdot Z), \quad Z \sim \mathcal{N}(0,1)
$$

With `scale=0.5`, the 5th and 95th percentiles are:
$$
\lambda_{P,5\%} = \exp(\mu - 1.645 \times 0.5), \quad \lambda_{P,95\%} = \exp(\mu + 1.645 \times 0.5)
$$

| Prior `mean` | 5th %ile (kN) | Median (kN) | 95th %ile (kN) |
|--------------|---------------|-------------|----------------|
| 1.5 | 2.0 | 4.5 | 10.0 |
| 2.5 | 5.4 | 12.2 | 27.2 |
| 3.0 | 9.0 | 20.1 | 44.9 |

With `mean=1.5`, some prior samples give $\lambda_P \approx 2$ kN, yielding ~5 independent regions over the 10 kN range‚Äîhence **wiggly curves**.

## Spectral Interpretation

The SE kernel has a Gaussian spectral density:
$$
S(\omega) = \sigma^2 \sqrt{2\pi} \lambda_P \exp\left(-\frac{\omega^2 \lambda_P^2}{2}\right)
$$

This means GP samples have:

- **Most power at low frequencies** (smooth, slowly-varying components)
- **Negligible power at frequencies** $\omega > 2/\lambda_P$

The **cutoff frequency** and corresponding minimum wavelength:
$$
\omega_{\text{cutoff}} \approx \frac{2}{\lambda_P}, \quad \text{Min wavelength} = \frac{2\pi}{\omega_{\text{cutoff}}} = \pi \lambda_P
$$

| $\lambda_P$ (kN) | Min wavelength (kN) | Oscillations in 10 kN |
|------------------|---------------------|------------------------|
| 2.0 | 6.3 | 1.6 |
| 4.5 | 14.1 | 0.7 |
| 12.2 | 38.3 | 0.26 |
| 20.1 | 63.1 | 0.16 |

With $\lambda_P = 2$ kN, the GP can generate ~1.6 oscillations; with $\lambda_P = 20$ kN, curves are essentially monotonic.

## Summary: Controlling Prior Wiggliness

To reduce wiggliness in prior prediction curves:

1. **Increase `lambda_P` prior mean**: Higher values enforce smoother functions
2. **Consider physical constraints**: Extension vs. Load should be approximately linear, suggesting $\lambda_P$ should be comparable to or larger than the data range
3. **Current recommendation**: `mean=3.0` gives median $\lambda_P \approx 20$ kN, ensuring smooth priors

# Posterior Prediction Uncertainty Bands

## Sources of Prediction Uncertainty

The full predictive distribution for a new observation $y_*$ includes three sources of uncertainty:

$$
y_* = f_* + \varepsilon
$$

where:

1. **Parameter uncertainty**: Uncertainty in $\theta = (E_1, E_2, \nu_{12}, \nu_{23}, G_{12})$
2. **GP epistemic uncertainty**: $\text{Var}[f_* | \text{Data}]$ ‚Äî uncertainty in the latent function
3. **Measurement noise**: $\varepsilon \sim \mathcal{N}(0, \sigma_{\text{noise}}^2)$ ‚Äî aleatory uncertainty

## Implementation: Dual Uncertainty Bands

The prediction code in `analyze.py` computes **both** types of uncertainty bands:

### Step 1: Sampling from the GP Posterior (Function Samples)

```python
# In posterior_predict (models.py):
L = jnp.linalg.cholesky(cov_post_emulator + jitter)
white_noise = random.normal(rng_key, (n_test,))
f_sample = L @ white_noise + mean_post_emulator  # Function sample

return mean_post, stdev_post, f_sample
```

This samples from the **latent function** $f_*$, capturing:

- ‚úÖ Parameter uncertainty (via sampling $\theta$ from posterior)
- ‚úÖ GP epistemic uncertainty (via Cholesky decomposition)
- ‚ùå Measurement noise (not yet included)

### Step 2: Adding Measurement Noise (Observation Samples)

```python
# In predict_batch (analyze.py):
# Compute noise variance based on noise model
if noise_model == "additive":
    noise_var = sig_meas[:, None]**2 * loads[None, :] + sig_meas_base[:, None]**2
elif noise_model == "constant":
    noise_var = sig_const[:, None]**2 * jnp.ones((n_samples, n_points))
else:  # proportional
    noise_var = sig_meas[:, None]**2 * loads[None, :]

# Sample measurement noise
noise_std = jnp.sqrt(noise_var)
noise_samples = noise_std * random.normal(rng_noise, (n_samples, n_points))

# Observation samples = function + noise
y_samples = f_samples + noise_samples
```

### Step 3: Computing Dual Percentile Bands

```python
# Function uncertainty (epistemic only)
pct_f = jnp.percentile(f_samples, q=[2.5, 97.5], axis=0)

# Observation uncertainty (includes noise)
pct_y = jnp.percentile(y_samples, q=[2.5, 97.5], axis=0)
```

## Mathematical Analysis

### Function Uncertainty

The function uncertainty band captures variance in the latent function $f_*$:

$$
\text{Var}[f_*] = \underbrace{\text{Var}_{\theta}[\mathbb{E}[f_* | \theta]]}_{\text{parameter uncertainty}} + \underbrace{\mathbb{E}_{\theta}[\text{Var}[f_* | \theta]]}_{\text{GP epistemic}}
$$

The first term captures uncertainty due to not knowing the true material parameters $\theta$. The second term captures GP interpolation uncertainty given fixed parameters.

### Observation Uncertainty

The observation uncertainty band captures variance in a new measurement $y_*$:

$$
\text{Var}[y_*] = \text{Var}[f_*] + \underbrace{\sigma^2_{\text{noise}}(P)}_{\text{measurement noise}}
$$

where the noise variance depends on the selected noise model:

| Noise Model | Formula | Configuration |
|-------------|---------|---------------|
| Proportional | $\sigma^2 = \sigma_{\text{measure}}^2 \cdot P$ | `"noise_model": "proportional"` |
| Additive | $\sigma^2 = \sigma_{\text{measure}}^2 \cdot P + \sigma_{\text{base}}^2$ | `"noise_model": "additive"` |
| Constant | $\sigma^2 = \sigma_{\text{constant}}^2$ | `"noise_model": "constant"` |

### Relationship Between Bands

Since $y_* = f_* + \varepsilon$ where $\varepsilon$ is independent noise:

$$
\text{Width}[\text{Observation Band}] \geq \text{Width}[\text{Function Band}]
$$

The observation band is always at least as wide as the function band, with the difference reflecting the measurement noise contribution.

## Interpreting the Visualization

The prediction plots display:

| Band | Color | Mathematical Interpretation |
|------|-------|----------------------------|
| **Inner (Function)** | Green fill, dashed borders | $\mathbb{P}(f_{2.5\%} \leq f_* \leq f_{97.5\%}) = 0.95$ |
| **Outer (Observation)** | Blue fill, dotted borders | $\mathbb{P}(y_{2.5\%} \leq y_* \leq y_{97.5\%}) = 0.95$ |

**Use cases:**

- **Function band**: "Where is the true mechanical response?"  
  Use for comparing with deterministic FE predictions or understanding material behaviour.

- **Observation band**: "What range of measurements should I expect?"  
  Use for experimental planning and validating model against held-out data.

## Configuration

Control band display via `configs/default_config.py`:

```python
"uncertainty_bands": "both",  # Options: "function", "observation", or "both"
```

# Practical Recommendations

## Prior Configuration

| Parameter | Current Value | Effect |
|-----------|---------------|--------|
| `lambda_P` mean | 2.5 | Smooth prior curves (median ~12 kN) |
| `sigma_emulator` rate | 100.0 | Expected value ~0.01 mm |
| `sigma_measure` rate | 1000.0 | Expected value ~0.001 |

## Controlling Prior Observation Band Width

The **prior observation bands** (blue outer bands in prior plots) can appear very wide. This width is determined by:

### 1. Physical Parameter Priors (Dominant Effect)

The `scale` values in `configs/default_config.py` control how much predictions vary:

```python
"reparam": {
    "E_1": {"mean": 154900.0, "scale": 5050.0},   # ¬±5050 MPa (3œÉ ‚âà ¬±15000)
    "E_2": {"mean": 10285.0, "scale": 650.0},     # ¬±650 MPa
    ...
}
```

Different Œ∏ samples produce different prediction curves. The spread of these curves drives band width.

### 2. Measurement Noise Prior (œÉ_measure)

```python
"sigma_measure": {"target_dist": dist.Exponential(1000.0)}  # mean = 0.001
```

For the **proportional noise model**: $\sigma^2 = \sigma_{\text{measure}}^2 \cdot P$

- Higher rate ‚Üí smaller expected œÉ_measure ‚Üí narrower observation bands
- Rate 100 gives mean ‚âà 0.01 (wider prior bands)
- Rate 1000 gives mean ‚âà 0.001 (narrower prior bands)

### 3. GP Epistemic Uncertainty

Without experimental data conditioning, the GP has high uncertainty. This contributes to both function and observation band width.

## Prior vs Posterior Band Behaviour

| Aspect | Prior Bands | Posterior Bands |
|--------|-------------|-----------------|
| **Function band** | Wide (unconstrained Œ∏, GP) | Narrow (Œ∏ and GP constrained by data) |
| **Observation band** | Wider (adds prior œÉ_measure samples) | Nearly same as function (œÉ_measure ‚Üí 0) |
| **Gap between bands** | Visible (prior œÉ_measure > 0) | Minimal (learned œÉ_measure ‚âà 0) |

**Key insight**: The posterior observation bands are narrow **not** because of a bug, but because the model learns that œÉ_measure ‚âà 0. The GP absorbs all residual variance into œÉ_emulator (see [Measurement Noise Identifiability](#measurement-noise-identifiability) below).


# Measurement Noise Identifiability

## The Observed Phenomenon

In practice, the posterior for `sigma_measure` often concentrates near zero:

| Parameter | Typical Posterior Mean |
|-----------|------------------------|
| `sigma_measure` | ~4.5e-05 (essentially zero) |
| `sigma_emulator` | ~0.014 |

This is a **variance decomposition / identifiability problem**, not a bug.

## The Additive Covariance Structure

The model constructs total covariance at experimental points as:

$$
\text{Cov}[y_i, y_j] = \sigma_{\text{emulator}}^2 \cdot k(\mathbf{x}_i, \mathbf{x}_j) + \sigma_{\text{measure}}^2 \cdot P_i \cdot \delta_{ij}
$$

where $\delta_{ij}$ is the Kronecker delta (noise only on diagonal).

The marginal variance at point $i$ is:
$$
\text{Var}[y_i] = \sigma_{\text{emulator}}^2 + \sigma_{\text{measure}}^2 \cdot P_i
$$

## Why The Model Prefers œÉ_emulator

### Correlation Structure

- **GP variance**: Explains residuals with **spatial correlation**‚Äîif one point deviates, nearby points also deviate
- **Measurement noise**: Explains residuals as **independent** at each point

With smooth underlying physics, residual patterns show correlation. The GP absorbs this into $\sigma_{\text{emulator}}$.

### The Length Scale Connection

With long length scales (e.g., $\lambda_P \approx 16$ kN > data range):

- GP function is nearly linear over one dataset
- GP can "flex" to follow trends
- Residuals appear correlated ‚Üí absorbed by $\sigma_{\text{emulator}}$

### Mathematical Identifiability

For the data to distinguish the two variance sources:

- Some points need **large P** (noise dominates): $\sigma_{\text{measure}}^2 \cdot P \gg \sigma_{\text{emulator}}^2$
- Some points need **small P** (GP dominates): $\sigma_{\text{emulator}}^2 \gg \sigma_{\text{measure}}^2 \cdot P$

With `max_load = 10 kN` and low noise, the proportional term $\sigma^2 \cdot P$ stays small.

## Connection to Other Issues

| Issue | Connection |
|-------|------------|
| Wiggly priors | Short $\lambda_P$ allowed GP to absorb measurement noise |
| Narrow posterior bands | If $\sigma_{\text{measure}} \approx 0$, noise adds nothing to bands |
| $\sigma_{\text{measure}} \approx 0$ | GP flexibility explains all residual variance |

## Implications

1. **Posterior bands are underestimated**: Missing the true observation noise
2. **Measurement precision not learned**: Cannot infer sensor accuracy from data
3. **Model is self-consistent**: GP explains data well, just not via the intended mechanism

# Future Work

## Planned Improvements

The following enhancements have been identified but not yet implemented:

### 1. Informative Prior for œÉ_measure

Set a minimum value based on known sensor physics/accuracy:

```python
# Example: Gaussian prior centered on known measurement precision
"sigma_measure": {
    "target_dist": dist.TruncatedNormal(loc=0.001, scale=0.0005, low=0.0)
}
```

**Rationale**: If sensor accuracy is known (e.g., ¬±0.001 mm), encode this as prior information.

### 2. Additive Noise Model Testing

Test the additive noise configuration:

```python
"noise_model": "additive"  # œÉ¬≤ = œÉ_measure¬≤ √ó P + œÉ_base¬≤
```

**Benefit**: The constant œÉ_base term provides more identifiable separation from the GP variance.

### 3. Tighter GP Priors

Further constrain the GP to force residual variance into measurement noise:

- Increase `sigma_emulator` prior rate (e.g., 50 or 100) to push values smaller
- This would force unexplained variance into œÉ_measure

### 4. Proper Prediction Intervals ‚úÖ IMPLEMENTED

**Status**: Implemented in `analyze.py` as of December 2025.

The prediction plots now show **dual uncertainty bands**:

- **Function uncertainty** (inner, green band): Uncertainty in the latent function $f_*$
- **Observation uncertainty** (outer, blue band): Uncertainty in a new observation $y_* = f_* + \varepsilon$

Configuration via `default_config.py`:

```python
"uncertainty_bands": "both"  # Options: "function", "observation", or "both"
```

Implementation details:

```python
# After GP function sampling (f_samples):
noise_std = jnp.sqrt(noise_var)
noise_samples = noise_std * random.normal(rng_noise, (n_samples, n_points))
y_samples = f_samples + noise_samples  # Observation samples with noise
```

## Priority

| Item | Priority | Effort | Status |
|------|----------|--------|--------|
| Informative œÉ_measure prior | High | Low | Pending |
| Additive noise testing | Medium | Low | Pending |
| Proper prediction intervals | High | Medium | ‚úÖ Done |
| Tighter GP priors | Low | Low | Pending |
| Band calibration investigation | High | Medium | üîç Open |

# Open Investigation: Band Calibration (90¬∞ Normal)

## Observed Issue

**Date**: December 2025

In the posterior prediction plot for **90¬∞ Normal direction**, some experimental data points fall outside both the function and observation uncertainty bands. For a well-calibrated 95% band, we expect ~5% of points outside. If significantly more points are outside, this indicates **model overconfidence**.

## Diagnosis

| Scenario | Expected | Implication |
|----------|----------|-------------|
| ~5% outside 95% band | ‚úì | Model is well-calibrated |
| Many points outside | ‚úó | Model is overconfident (underestimates uncertainty) |

## Root Cause

Since **œÉ_measure ‚Üí 0** in the posterior (GP absorbs variance), the observation band ‚âà function band. If genuine measurement noise exists but isn't captured, bands will be too narrow.

## Next Steps

1. **Run residual analysis**: Set `run_residual_analysis: True` and check if standardized residuals are within ¬±2
2. **Try informative œÉ_measure prior**: Use `dist.TruncatedNormal(loc=0.001, scale=0.0005, low=0.0)` to prevent collapse to zero
3. **Check 90¬∞ Normal specifically**: Investigate if this direction has unusual noise or systematic bias
4. **Compare noise models**: Test `"noise_model": "additive"` for better identifiability

# Model Analysis: src/core/models.py



This document provides a detailed analysis of the two active model definitions in `src/core/models.py` (`model_n` and `model_n_hv`) and the likelihood function.

## 1. Model Comparison

The file contains three distinct model formulations. The key differences lie in their **parameterization strategy** (Centered vs. Non-Centered), **data handling** (Single vs. Multi-output), and **prior distributions**.

| Feature | `model_n` | `model_n_hv` |
| :--- | :--- | :--- |
| **Type** | Reparameterized | Multi-Output Reparameterized |
| **Parameterization** | **Non-Centered**<br>Parameters sampled from $N(0,1)$ and scaled. | **Non-Centered**<br>Parameters sampled from $N(0,1)$ and scaled. |
| **Outputs** | Single (Switchable S/N) | **Dual (Shear & Normal)** |
| **Mean Function** | $P \sin(\alpha)$ OR $P \cos(\alpha)$ | $P \sin(\alpha)$ AND $P \cos(\alpha)$ |
| **Priors** | **Current** | **Current** |

### Detailed Prior Comparison

A critical difference is that `model_n_hv` uses a different set of physical priors compared to `model` and `model_n`.

| Parameter | Original / Legacy (Set A) | Current (Set B) | Change Analysis |
| :--- | :--- | :--- | :--- |
| **$E_1$** | $161,000 \pm 2,000$ | $154,900 \pm 5,050$ | **Mean $\downarrow$, Uncertainty $\uparrow \times 2.5$** |
| **$E_2$** | $11,380 \pm 100$ | $10,285 \pm 650$ | Mean $\downarrow$, Uncertainty $\uparrow$ |
| **$\nu_{12}$** | $0.32 \pm 0.01$ | $0.33 \pm 0.015$ | Mean $\uparrow$ |
| **$\nu_{23}$** | $0.43 \pm 0.01$ | $0.435 \pm 0.0125$ | Mean $\approx$ |
| **$G_{12}$** | $5,170 \pm 70$ | $5,115 \pm 98$ | Mean $\downarrow$ |

### Understanding `_n` Parameters

You may notice parameters with an `_n` suffix (e.g., `sigma_emulator_n`, `E_1_n`). These are **coupled** but not typically "clones" of their counterparts.

*   **`param_n`** is the **normalized** latent variable sampled by the MCMC (usually $\sim \mathcal{N}(0, 1)$).
*   **`param`** is the **physical** value derived from it: $\theta = \mu + \sigma \cdot \theta_n$ (for Normal) or similar transformations.

They contain the same information (one is a deterministic function of the other), but their plots show the distribution on different scales (Standard Normal vs. Physical Units). The `_n` plots are useful for checking convergence (should look like a "fuzzy caterpillar" around 0).

> [!NOTE]
> `model_n_hv` assumes significantly higher uncertainty for $E_1$ but tighter constraints on $\nu_{12}$.

### Hyperparameter Priors

In addition to the physical parameters, the model also estimates hyperparameters governing the Gaussian Process emulator and measurement noise. These are consistent across all models (though `model_n` and `model_n_hv` use reparameterization).

| Hyperparameter | Description | Prior Distribution |
| :--- | :--- | :--- |
| **$\mu_{emulator}$** | GP Mean Offset | $\mathcal{N}(0, 0.01)$ |
| **$\sigma_{emulator}$** | GP Amplitude | $\text{Exponential}(20.0)$ |
| **$\sigma_{measure}$** | Measurement Noise | $\text{Exponential}(100.0)$ |
| **$\lambda_P$** | Length Scale (Load) | $\text{LogNormal}(1.5, 0.5)$ |
| **$\lambda_\alpha$** | Length Scale (Angle) | $\text{LogNormal}(0.34, 0.5)$ |
| **$\lambda_{E1}$** | Length Scale ($E_1$) | $\text{LogNormal}(11.0, 0.5)$ |
| **$\lambda_{E2}$** | Length Scale ($E_2$) | $\text{LogNormal}(8.3, 0.5)$ |
| **$\lambda_{\nu12}$** | Length Scale ($\nu_{12}$) | $\text{LogNormal}(-0.80, 0.5)$ |
| **$\lambda_{\nu23}$** | Length Scale ($\nu_{23}$) | $\text{LogNormal}(-0.80, 0.5)$ |
| **$\lambda_{G12}$** | Length Scale ($G_{12}$) | $\text{LogNormal}(7.7, 0.5)$ |

*Note: The length scales $\lambda$ determine how quickly the model discrepancy changes with respect to changes in inputs or parameters. A small length scale implies a "wiggly" function, while a large one implies a smooth function.*

### Bias Modeling

The code also supports adding bias terms to account for systematic discrepancies in specific parameters. This is modeled hierarchically:

1.  **Global Scale Parameter**: A global scale $\sigma_b$ is sampled from an Exponential prior.
2.  **Experiment-Specific Bias**: For each experiment $i$, a specific bias $b_i$ is sampled from $\mathcal{N}(0, \sigma_b)$.
3.  **Application**:
    *   **$E_1$ Bias**: Added to the parameter samples for each experiment before emulation.
    *   **$\alpha$ Bias**: Added to the angle input for each experiment.

| Bias Type | Prior for Scale $\sigma_b$ | Implied Mean of Scale | Physical Interpretation |
| :--- | :--- | :--- | :--- |
| **$E_1$ Bias** ($b_{E1}$) | $\text{Exponential}(0.001)$ | $1,000 \text{ MPa}$ | Accounts for variability in stiffness between experiments. |
| **$\alpha$ Bias** ($b_{\alpha}$) | $\text{Exponential}(1 / \text{rad}(10^\circ))$ | $0.1745 \text{ rad} \approx 10^\circ$ | Accounts for misalignment of the specimen fibers. |

*Note: The rate parameter for $\alpha$ bias is $1 / (10 \cdot \frac{\pi}{180}) \approx 5.73$.*


## 2. Likelihood Analysis

All models use a **Gaussian Process (GP) Likelihood**. The observed data $\mathbf{y}$ is modeled as coming from a Multivariate Normal distribution:

$$ \mathbf{y} \sim \mathcal{N}(\boldsymbol{\mu}(\mathbf{x}, \theta), \mathbf{K}(\mathbf{x}, \theta) + \mathbf{\Sigma}_\epsilon) $$

Where:

*   $\boldsymbol{\mu}(\mathbf{x}, \theta)$: The physics-based mean function (Finite Element surrogate).
*   $\mathbf{K}(\mathbf{x}, \theta)$: The GP covariance matrix representing emulator uncertainty (bias).
*   $\mathbf{\Sigma}_\epsilon$: Measurement noise matrix. Note that the noise variance is **proportional to the load**: $\mathbf{\Sigma}_{ii} = \sigma_{measure}^2 \times P_i$.

*   $\mathbf{\Sigma}_\epsilon$: Measurement noise matrix. Note that the noise variance is **proportional to the load**: $\mathbf{\Sigma}_{ii} = \sigma_{measure}^2 \times P_i$.

### 2.1 Experimental Data Aggregation

> [!IMPORTANT]
> **Data Usage Note**: The current Bayesian analysis uses **averaged experimental data** for the likelihood calculation.

The raw experimental data contains measurements from three sensor positions (Left, Center, Right) for each load step. However, the current inference input ($\mathbf{y}$) is constructed by **averaging** these three values into a single mean extension per load step.

*   **Current State**: Likelihood is computed against the mean response: $\mathbf{y}_i = \frac{1}{3} (y_{i,L} + y_{i,C} + y_{i,R})$.
*   **Future Capability**: The code retains the raw positional data in the data loading pipeline (`data_loader.py` returns `_raw` arrays). This allows for future extensions where the likelihood could explicitly model the separate sensor outputs, potentially to capture asymmetric effects or sensor-specific noise.

### The `model_n_hv` Likelihood (Dual Output)

The `model_n_hv` function is unique because it performs **Multi-Output Inference**. It evaluates the likelihood of observing both Shear ($S$) and Normal ($N$) extensions simultaneously for a given set of material parameters.

#### A. Conditional Independence
The model assumes that given the true material parameters $\theta$ and the GP emulator state, the residuals for Shear and Normal data are independent. The total log-likelihood is the sum of the individual log-likelihoods:

$$ \log P(\mathbf{y}_h, \mathbf{y}_v | \theta) = \log P(\mathbf{y}_h | \theta) + \log P(\mathbf{y}_v | \theta) $$

In the code:
```python
# Sample Shear
mu_s, sigma_s = gp_predict(..., direction='h') # Shear (formerly Horizontal)
# Likelihood(Data_Shear | mu_s, sigma_s)

# Sample Normal
mu_n, sigma_n = gp_predict(..., direction='v') # Normal (formerly Vertical)
# Likelihood(Data_Normal | mu_n, sigma_n)
```

#### B. Physical Coupling (The "Why")
Although the likelihood statements are separate, the inference is **strongly coupled** via the shared parameters:

1.  **Shared Physics ($\theta$)**: The same $E_1, E_2, \dots$ must explain both the shear deformation ($H$) and the normal deformation ($V$).
    *   $\boldsymbol{\mu}_h = \text{Emulator}(\theta) \cdot P \sin(\alpha)$
    *   $\boldsymbol{\mu}_v = \text{Emulator}(\theta) \cdot P \cos(\alpha)$
    *   *Effect*: This constrains the parameter space significantly. A parameter set that fits $H$ well but $V$ poorly will have a low total likelihood.

2.  **Shared Emulator Structure ($\mathbf{K}$)**:
    *   The covariance matrix $\mathbf{K}$ is identical for both outputs.
    *   *Effect*: The model assumes the "smoothness" and "scale" of the model discrepancy is similar for both directions.

3.  **Shared Noise Model**:
    *   A single `sigma_measure` is used for both.
    *   *Effect*: Assumes similar sensor noise characteristics for both measurement types.

### 3. Code Implementation Details

### Centered vs. Non-Centered Parameterization

The codebase exclusively uses **Non-Centered parameterization** to ensure sampling efficiency.

**Non-Centered (`model_n`, `model_n_hv`)**:
```python
# Easier for MCMC (Standard Normal)
x_n = numpyro.sample("x_n", dist.Normal(0, 1))
x = mu + sigma * x_n
numpyro.deterministic("x", x)
```
*Why?* This decouples the dependency between the mean/scale and the sample value, avoiding "funnel" pathologies in the posterior geometry, leading to more efficient sampling.

#### Directional Logic

*   **`model`**: Hardcoded to $\sin(\alpha)$ (Shear).
*   **`model_n`**: Checks `if direction == 'h'` to choose between $\sin$ and $\cos$.
*   **`model_n_hv`**: Computes **both** and samples **both**.

```python
# model_n_hv logic
mean_vector_h = mean_emulator * input_xy[:,0] * jnp.sin(input_xy[:,1])
mean_vector_v = mean_emulator * input_xy[:,0] * jnp.cos(input_xy[:,1])
```

### Proportional Noise Model (Default)

By default, the codebase assumes a measurement noise variance proportional to load (`noise_model: "proportional"`):
$$ \sigma_{\text{noise}}^2 = \sigma_{\text{measure}}^2 \cdot P $$
where $P$ is the load.

This model assumes **heteroscedasticity**: as the load increases, the physical variability (and thus error) increases naturally. This is consistent with many mechanical testing scenarios where error is a percentage of the signal.

### Additive Noise Model (Optional)

An optional **Additive Noise Model** (`noise_model: "additive"`) is available to handle cases where noise persists at zero load:
$$ \sigma_{\text{noise}}^2 = \sigma_{\text{measure}}^2 \cdot P + \sigma_{\text{base}}^2 $$

-   **$\sigma_{\text{base}}$**: Represents the "base" or "background" noise variance that is independent of load.
-   **Configuration**: This can be enabled in `defaults_config.py` by setting `"data": {"noise_model": "additive"}`.
-   **Prior**: The prior for $\sigma_{\text{base}}$ can be configured under `"priors" -> "simga_measure_base"`.

### Understanding Priors for Additive Noise

When using the additive noise model, you might notice that `sigma_measure` (proportional) and `sigma_measure_base` (constant) can have similar numerical priors (e.g., `Exponential(100)`), despite representing different physical concepts. This is due to the units involved in the variance equation:

$$ \sigma_{\text{total}}^2 = \sigma_{\text{measure}}^2 \cdot P + \sigma_{\text{base}}^2 $$

1.  **$\sigma_{\text{base}}$ (Base Noise)**:
    *   This term has the **same units as the data** (e.g., mm).
    *   If measurement noise is small (e.g., $\approx 0.01$ mm), then $\sigma_{\text{base}} \approx 0.01$.
    *   A prior like `Exponential(100)` implies a mean of $1/100 = 0.01$, which is appropriate for this small scale.

2.  **$\sigma_{\text{measure}}$ (Proportional Term)**:
    *   This term is multiplied by Load ($P$).
    *   For the units to be consistent ($\text{mm}^2$), $\sigma_{\text{measure}}^2$ must have units of $\text{mm}^2 / \text{kN}$.
    *   If the typical Load $P \approx 10$ kN, then $\sigma_{\text{measure}}^2 \cdot 10 \approx \sigma_{\text{base}}^2$.
    *   This implies $\sigma_{\text{measure}}$ should be smaller than $\sigma_{\text{base}}$ by a factor of $\sqrt{P}$.
    *   However, if we use a loose prior (like `Exponential(1.0)` with mean 1.0), the model may overestimate noise. Using a tighter prior like `Exponential(100)` for this term as well acts as a conservative regularizer, ensuring the proportional noise component remains physically realistic.

### Constant Variance Noise Model

A third option is the **Constant Variance Noise Model** (`noise_model: "constant"`):

$$ \sigma_{\text{noise}}^2 = \sigma_{\text{constant}}^2 $$

-   **Assumption**: The noise variance is practically constant and does not depend on the load mechanism. This is effectively a standard homoscedastic Gaussian noise model.
-   **Configuration**: Set `"data": {"noise_model": "constant"}` in `default_config.py`.

-   **Prior**: The prior for $\sigma_{\text{constant}}$ is configured under `"priors" -> "sigma_constant"`.

## Appendix: Legacy Design Decision - Dropping Centered Parameterization

Based on literature regarding Hamiltonian Monte Carlo and NUTS, the centered `model` was dropped in favor of the non-centered (reparameterized) versions (`model_n` / `model_n_hv`).

**Reasoning:**

1.  **The "Funnel" Problem**:
    *   **Literature**: In hierarchical models (like Gaussian Processes with learnable length scales), centered parameterizations ($\theta \sim N(\mu, \sigma)$) essentially create a geometry known as "Neal's Funnel."
    *   **The Issue**: The curvature of the posterior distribution changes drastically depending on the value of the hyperparameters. NUTS (the sampler used by NumPyro) struggles to explore the "neck" of this funnel, leading to divergences and very low Effective Sample Sizes (ESS).
    *   **Solution**: Non-centered parameterization (sampling $\theta_{raw} \sim N(0,1)$ and scaling it) "whitens" the geometry, making it much easier for the sampler to navigate.

2.  **Efficiency**:
    *   For the type of GP inference performed here (learning separate length scales and variances), the non-centered implementations (`model_n`) will almost always converge faster and produce more reliable chains than the centered `model`.


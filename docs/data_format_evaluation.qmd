---
title: "Data Format Evaluation: HDF5 vs. NetCDF (ArviZ)"
format:
  html:
    theme: cosmo
    toc: true
  pdf:
    geometry:
      - top=30mm
      - left=30mm
---


## Current Workflow (HDF5)
The current workflow in `MAF_gp_hv.py` and `posterior_no_bias.ipynb` uses HDF5 (`h5py`) to store and retrieve MCMC samples.

**Pros:**
- Simple to implement for basic array storage.
- Fast I/O.
- No additional dependencies beyond `h5py` (which is standard).

**Cons:**
- **Lack of Structure**: Samples are stored as flat datasets. Dimensions like `chain` and `draw` are often flattened or require manual management.
- **Manual Metadata**: You have to manually track what each dimension corresponds to (e.g., which index is which experiment).
- **Manual Diagnostics**: You must manually calculate ESS, R-hat, and HPDI using `numpyro.diagnostics` or custom code.
- **Boilerplate Plotting**: Plotting requires manually extracting arrays and setting up Matplotlib figures.

## Proposed Workflow (NetCDF / ArviZ)
NumPyro integrates well with [ArviZ](https://arviz-devs.github.io/arviz/), a library for exploratory analysis of Bayesian models. ArviZ uses NetCDF as its backend storage format.

**Pros:**
- **InferenceData Object**: A single, structured object containing:
    - `posterior`: The MCMC samples.
    - `posterior_predictive`: Generated data from the model.
    - `observed_data`: The actual experimental data used.
    - `log_likelihood`: For model comparison (WAIC, LOO).
    - `sample_stats`: Divergences, acceptance probabilities, etc.
- **Labeled Dimensions**: You can name dimensions (e.g., `experiment`, `sensor_location`) instead of using integer indices.
- **Built-in Diagnostics**: One-line commands for `az.summary()`, `az.rhat()`, `az.ess()`.
- **Rich Plotting**: `az.plot_trace()`, `az.plot_posterior()`, `az.plot_forest()`, `az.plot_ppc()` (posterior predictive check).
- **Standardization**: NetCDF is a self-describing format, making results easier to share and understand later.

## Recommendation
**Switch to ArviZ/NetCDF.**

While HDF5 is sufficient for raw storage, adopting ArviZ `InferenceData` (saved as NetCDF) will significantly streamline post-processing in `posterior_no_bias.ipynb`. It eliminates the need for manual array slicing and boilerplate plotting code, and provides robust diagnostics out of the box.

### Implementation Steps
1.  **In `MAF_gp_hv.py`**:
    ```python
    import arviz as az
    # ... after mcmc.run() ...
    idata = az.from_numpyro(mcmc)
    az.to_netcdf(idata, "results_mcmc/model_results.nc")
    ```
2.  **In `posterior_no_bias.ipynb`**:
    ```python
    import arviz as az
    idata = az.from_netcdf("results_mcmc/model_results.nc")
    az.plot_trace(idata, var_names=["E_1", "E_2"])
    az.summary(idata)
    ```
